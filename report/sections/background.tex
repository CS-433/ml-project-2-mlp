% Some important notes from the homepage2vec paper
% 1) Intro
% Before homepage2vec
% - No multilingual models
% - No embeddings based methods
% - Usually paid services
% With Homepage2vec
% - multilingual -> great because out of top 10M websites, 40% are not in English
% - embeddings based
% - open source
% - fast since you can run it locally, and do not have to use external API

% 2) Related work
% Related approaches
% - manual approaches back in the days
% - ML based methods that use contextual features of the given webpage
% - Methods that also use for context the surrounding webpages, especially useful when the current page does not include that much info
% - Methods that use vision features
% - Recently, use of the LSTM, BERT, GRU architectures -> shown to increase performance -> however focus purely on English

% Multilingual embeddings
% - They are using XML-R, multi-lingual model, that has shown to be comparable to the monolingual models

% 3) Dataset
% - Curlie = community edited web directory -> 3M websites in 92 languages,
% labeled in hierarchical categories, however they only used the top level categories
% Originally, there were 15 top level categories, but they dropped "Regional"
% - Majority of classes associated with Bussiness (27), Society (13.9) or Arts (9)
% - 40% of the websites are in English, 16 % in German, 5% in french, 6% in Japanese
% - Although each page may, in principle, have an arbitrary number of category labels, 
% at the top level, the data is mostly single-labeled, with only 2.1% of samples appearing 
% in two or more taxonomy trees of the 14 top-level classes.

% 4) Method
% - They embeded only the first 100 sentences since the embedding process is quite expensive
% This was selected based on the validation set performance using the elbow method
% - They use 19 most frequent domains exluding the domains that indicate country
% - Title, description and keywords are used as well and should be very informative
% - With the links, they use the anchor text and the 50 most frequent texts are used, again
% this was selected using the elbow method

% 5) Main limitations and challenges of homepage2vec
% 


% Background:
% - Homepage2Vec: Motivation, model, results + limitations (mismatch in label distribution between training and true)
% - GPT annotations (references from literature <- for ludek)
\section{background}\label{sec:background}
\textbf{Homepage2Vec} addresses the limitations in existing approaches to web page representation by introducing a multilingual, embeddings-based model. Prior to its development, there were no multilingual models or widely adopted embedding-based methods for web page analysis. Often, web page analysis relied on paid services. Homepage2Vec revolutionizes this landscape by offering a multilingual, open-source solution based on embeddings. Additionally, the model is efficient, allowing for local execution without the need for external APIs, making it accessible and fast for a diverse range of users.

\texttt{Homepage2Vec} is trained on Curlie which is a publicly available directory of websites and corresponding labels maintained by a volunteer community. As 


The model first parses the raw html into \textit{top-level-domain}, \textit{domain}, \textit{metatags}, \textit{title}, \textit{description}, \textit{keywords}, \textit{links} and \textit{sentences}.

