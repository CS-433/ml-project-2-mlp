{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noqa: E402\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import rootutils\n",
    "import hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize hydra on every run\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "h = hydra.initialize(config_path=\"../conf\", job_name=\"eda\", version_base=None)\n",
    "\n",
    "# Setup root environment\n",
    "root_path = rootutils.setup_root(\".\")\n",
    "rootutils.set_root(\n",
    "    path=root_path,\n",
    "    project_root_env_var=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costs per token based on https://openai.com/pricing\n",
    "GPT4_COST_PER_INP_TOKEN = 0.00001\n",
    "GPT4_COST_PER_OUT_TOKEN = 0.00003\n",
    "GPT3_5_COST_PER_INP_TOKEN = 0.000001\n",
    "GPT3_5_COST_PER_OUT_TOKEN = 0.000002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Websites\n",
    "\n",
    "---\n",
    "\n",
    "There are three copora of websites in this dataset:\n",
    "\n",
    "* `original`: 770 websites from the crowdsourced dataset from the [Homepage2Vec paper](https://arxiv.org/abs/1905.09786)\n",
    "* `gpt`: 250 common websites obtained by prompting GPT-4 (see [Prompts](https://chat.openai.com/share/a76c8b9b-a659-4b15-9ab0-d94af4733d58))\n",
    "* `curlie`: A filtered version of the [curlie](https://curlie.org) dataset, containing ~1M websites\n",
    "\n",
    "For each website, the repository contains a CSV file at the path `data/raw/<corpus>.csv` with the two columns - `wid` and `url`. The `wid` is a unique identifier for the website, and the `url` is the URL of the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Config\n",
    "original_cfg = hydra.compose(config_name=\"eda\", overrides=[\"data=original\"])\n",
    "gpt_cfg = hydra.compose(config_name=\"eda\", overrides=[\"data=gpt\"])\n",
    "curlie_cfg = hydra.compose(config_name=\"eda\", overrides=[\"data=curlie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes\n",
    "path = os.path.join(root_path, \"data\", \"meta\", \"categories.txt\")\n",
    "with open(path) as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data\n",
    "\n",
    "This is the data that was used to test the model in the original paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "original_data = hydra.utils.instantiate(original_cfg.data)\n",
    "\n",
    "raw_data = original_data.get_raw_data()\n",
    "processed_data = original_data.get_processed_data()\n",
    "embedded_data = original_data.get_embeddings()\n",
    "\n",
    "print(f\"Total number of samples: {len(raw_data)}\")\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processed website\n",
    "wid = list(processed_data.keys())[0]\n",
    "data = processed_data[wid]\n",
    "\n",
    "print(f\"Collected data on {list(data.keys())}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nTitle: {data['title']}\")\n",
    "print(f\"Description: {data['description']}\")\n",
    "print(f\"Keywords: {data['keywords']}\")\n",
    "print(f\"Tags: {data['metatags']}\")\n",
    "print(f\"Domain: {data['domain']}\")\n",
    "print(f\"TLD: {data['tld']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_featues(feat):\n",
    "    return len([w[feat] for w in processed_data.values() if w[feat] is not None and w[feat] != []])\n",
    "\n",
    "n = len(processed_data)\n",
    "n_tld = get_num_featues(\"tld\")\n",
    "n_domain = get_num_featues(\"domain\")\n",
    "n_tags = get_num_featues(\"metatags\")\n",
    "n_titles = get_num_featues(\"title\")\n",
    "n_descriptions = get_num_featues(\"description\")\n",
    "n_keywords = get_num_featues(\"keywords\")\n",
    "n_links = get_num_featues(\"links\")\n",
    "\n",
    "# Print results\n",
    "print(f\"ℹ️ Number of sites with TLD: {n_tld/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with domain: {n_domain/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with tags: {n_tags/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with title: {n_titles/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with description: {n_descriptions/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with keywords: {n_keywords/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with links: {n_links/n*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "gpt_data = hydra.utils.instantiate(gpt_cfg.data)\n",
    "\n",
    "raw_data = gpt_data.get_raw_data()\n",
    "processed_data = gpt_data.get_processed_data()\n",
    "embedded_jdata = gpt_data.get_embeddings()\n",
    "\n",
    "print(f\"Total number of samples: {len(raw_data)}\")\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processed website\n",
    "wid = list(processed_data.keys())[0]\n",
    "data = processed_data[wid]\n",
    "\n",
    "print(f\"Collected data on {list(data.keys())}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nTitle: {data['title']}\")\n",
    "print(f\"Description: {data['description']}\")\n",
    "print(f\"Keywords: {data['keywords']}\")\n",
    "print(f\"Tags: {data['metatags']}\")\n",
    "print(f\"Domain: {data['domain']}\")\n",
    "print(f\"TLD: {data['tld']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_featues(feat):\n",
    "    return len([w[feat] for w in processed_data.values() if w[feat] is not None and w[feat] != []])\n",
    "\n",
    "n = len(processed_data)\n",
    "n_tld = get_num_featues(\"tld\")\n",
    "n_domain = get_num_featues(\"domain\")\n",
    "n_tags = get_num_featues(\"metatags\")\n",
    "n_titles = get_num_featues(\"title\")\n",
    "n_descriptions = get_num_featues(\"description\")\n",
    "n_keywords = get_num_featues(\"keywords\")\n",
    "n_links = get_num_featues(\"links\")\n",
    "\n",
    "# Print results\n",
    "print(f\"ℹ️ Number of sites with TLD: {n_tld/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with domain: {n_domain/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with tags: {n_tags/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with title: {n_titles/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with description: {n_descriptions/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with keywords: {n_keywords/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with links: {n_links/n*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "curlie_data = hydra.utils.instantiate(curlie_cfg.data)\n",
    "\n",
    "raw_data = curlie_data.get_raw_data()\n",
    "processed_data = curlie_data.get_processed_data()\n",
    "embedded_jdata = curlie_data.get_embeddings()\n",
    "\n",
    "print(f\"Total number of samples: {len(raw_data)}\")\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processed website\n",
    "wid = list(processed_data.keys())[0]\n",
    "data = processed_data[wid]\n",
    "\n",
    "print(f\"Collected data on {list(data.keys())}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nTitle: {data['title']}\")\n",
    "print(f\"Description: {data['description']}\")\n",
    "print(f\"Keywords: {data['keywords']}\")\n",
    "print(f\"Tags: {data['metatags']}\")\n",
    "print(f\"Domain: {data['domain']}\")\n",
    "print(f\"TLD: {data['tld']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_featues(feat):\n",
    "    return len([w[feat] for w in processed_data.values() if w[feat] is not None and w[feat] != []])\n",
    "\n",
    "n = len(processed_data)\n",
    "n_tld = get_num_featues(\"tld\")\n",
    "n_domain = get_num_featues(\"domain\")\n",
    "n_tags = get_num_featues(\"metatags\")\n",
    "n_titles = get_num_featues(\"title\")\n",
    "n_descriptions = get_num_featues(\"description\")\n",
    "n_keywords = get_num_featues(\"keywords\")\n",
    "n_links = get_num_featues(\"links\")\n",
    "\n",
    "# Print results\n",
    "print(f\"ℹ️ Number of sites with TLD: {n_tld/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with domain: {n_domain/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with tags: {n_tags/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with title: {n_titles/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with description: {n_descriptions/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with keywords: {n_keywords/n*100:.2f}%\")\n",
    "print(f\"ℹ️ Number of sites with links: {n_links/n*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelers\n",
    "\n",
    "---\n",
    "\n",
    "There are multiple GPT labeler instances that can be used to label the data. The labelers are defined in the labelers module. These are:\n",
    "\n",
    "* `human`: Uses human labels from the [Homepage2Vec paper](https://arxiv.org/abs/1905.09786) -- only works for the `original` corpus\n",
    "* `gpt-labeler1`: Uses information on the `tld`, `domain`, `metatags`\n",
    "* `gpt-labeler2`: Uses information like `gpt-labeler1` +  `title`, `description`, `keywords`\n",
    "* `gpt-labeler3`: Uses information like `gpt-labeler2` +  `links` and `text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Quality\n",
    "\n",
    "The goal of all GPT labelers is to replicate the ground truth labels provide by the human annotators as closely as possible. As we only have human annotations for the original dataset, we can only evaluate the labelers on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise configuration for all labelers\n",
    "labeler_names = [\"human\", \"gpt3.5-context0\", \"gpt3.5-context1\", \"gpt3.5-context2\", \"gpt3.5-context3\"] \n",
    "\n",
    "original_labeler_cfg = {labeler: hydra.compose(config_name=\"eda\", overrides=[f\"labeler={labeler}\"]) for labeler in labeler_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data\n",
    "original_data = hydra.utils.instantiate(original_cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate labelers\n",
    "labelers = {labeler: hydra.utils.instantiate(cfg.labeler, data=original_data) for labeler, cfg in original_labeler_cfg.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the labelers are working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processed_websites = len(original_data.get_processed_data())\n",
    "\n",
    "print(f\"ℹ️ Number of processed websites: {num_processed_websites}\")\n",
    "for name, labeler in labelers.items():\n",
    "    num_labels = len(labeler.get_labels())\n",
    "    print(f\"ℹ️ Number of {name} labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense - the GPT labelers only provide labels for the websites that could be scraped, which is 761, while the ground truth labels are provided for all 840 websites. We will have to match the labels by the website ID accordingly when we evaluate the labelers. Next, we will process the returned GPT labels - we will iterate over all the websites in the original dataset, and collect all valid annotations and give an overview of the reasons for invalid labels - if there are any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(labeler):\n",
    "    match labeler.name:\n",
    "        case \"human\":\n",
    "            valid_labels = {wid: website[\"labels\"] for wid, website in labeler.get_labels().items()}\n",
    "            return valid_labels, [], 0\n",
    "        case _:\n",
    "            valid_labels = {}\n",
    "            invalid_labels = []\n",
    "            total_duration = 0\n",
    "            for wid, website in labeler.get_labels().items():\n",
    "                if website[\"is_valid\"]:\n",
    "                    valid_labels[wid] = website[\"labels\"]\n",
    "                else:\n",
    "                    invalid_labels.append(website[\"reason_invalid\"])\n",
    "                total_duration += website[\"duration\"]\n",
    "            avg_duration = total_duration / len(labeler.get_labels())\n",
    "            return valid_labels, invalid_labels, avg_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for name, labeler in labelers.items():\n",
    "    valid_labels, reasons_invalid, avg_duration = process_labels(labeler)\n",
    "    print(f\"ℹ️ {name}: Valid {len(valid_labels)}, Invalid: {len(reasons_invalid)}. Avg. Duration: {avg_duration:.2f}s\")\n",
    "    labels[name] = valid_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, most labels are valid. Let's now match the labels of the GPT labelers with the human labels by the website id (wid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_labels(labels1, labels2, subset = None):\n",
    "    wid1 = set(labels1.keys())\n",
    "    wid2 = set(labels2.keys())\n",
    "    matched_wid = wid1 & wid2\n",
    "    if subset:\n",
    "        matched_wid = matched_wid & subset\n",
    "\n",
    "    labels1 = [labels1[wid] for wid in matched_wid]\n",
    "    labels2 = [labels2[wid] for wid in matched_wid]\n",
    "\n",
    "    return labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of gpt-labeler1\n",
    "labels1, labels2 = match_labels(labels[\"human\"], labels[\"gpt3.5-context1\"])\n",
    "print(classification_report(labels1, labels2, zero_division=0, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of gpt-labeler2\n",
    "labels1, labels2 = match_labels(labels[\"human\"], labels[\"gpt3.5-context2\"])\n",
    "print(classification_report(labels1, labels2, zero_division=0, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of gpt-labeler3\n",
    "labels1, labels2 = match_labels(labels[\"human\"], labels[\"gpt3.5-context3\"])\n",
    "print(classification_report(labels1, labels2, zero_division=0, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the accuracy for websites that contained all the features for context2\n",
    "wids = set(map(str, [wid for wid, website in original_data.get_processed_data().items() if website[\"title\"] is not None and website[\"description\"] is not None and website[\"keywords\"] is not None]))\n",
    "\n",
    "# Accuracy of gpt-labeler3\n",
    "labels1, labels2 = match_labels(labels[\"human\"], labels[\"gpt3.5-context2\"], subset=wids)\n",
    "print(classification_report(labels1, labels2, zero_division=0, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "import numpy as np\n",
    "\n",
    "def get_class_dist(labeler, classes=None):\n",
    "    labels = np.array([website[\"labels\"] for _, website in labeler.get_labels().items()])\n",
    "\n",
    "    if classes:\n",
    "        return {label: count for label, count in zip(classes, labels.sum(0))}\n",
    "    else:\n",
    "        return {label: count for label, count in zip(range(labels.shape[1]), labels.sum(0))}\n",
    "\n",
    "\n",
    "class_dists = {name: get_class_dist(labeler, classes=classes) for name, labeler in labelers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for labeler in labeler_names:\n",
    "    class_dist = class_dists[labeler]\n",
    "    for c in classes:\n",
    "        rows.append({\"labeler\": labeler, \"category\": c, \"count\": class_dist[c]})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "sns.barplot(\n",
    "    df,\n",
    "    x=\"category\",\n",
    "    y=\"count\",\n",
    "    hue=\"labeler\",\n",
    "    ax=ax\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-2-mlp-a6NSXBdT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
