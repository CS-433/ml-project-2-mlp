{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "This notebook shows how to download/ load the data and models which are used in\n",
    "this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# External imports\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Internal imports\n",
    "import ml_project_2_mlp.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Homepage2Vec model\n",
    "homepage2vec_path = os.path.join(os.path.join(\"..\", \"models\"), \"homepage2vec\")\n",
    "expected_files = [\"features.txt\", \"model.pt\"]\n",
    "os.system(f\"rm {homepage2vec_path}/*\")\n",
    "\n",
    "start = time.time()\n",
    "utils.download_if_not_present(\n",
    "    dir_path=homepage2vec_path,\n",
    "    gdrive_url=\"https://drive.google.com/u/2/uc?id=1bE8ttkcgH9nMCobXIjPx05ezipklvsJ3&export=download\",\n",
    "    expected_files=expected_files\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ (Down)loaded homepage2vec model ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "start = time.time()\n",
    "model, features = utils.load(\n",
    "    dir_path=homepage2vec_path,\n",
    "    expected_files=[\"model.pt\", \"features.txt\"],\n",
    ")\n",
    "print(f\"✅ Loaded homepage2vec model ({(time.time() - start):.2f}s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Raw Crowdsourced data\n",
    "raw_crowdsourced_data_path = os.path.join(\"..\", \"data\", \"crowdsourced\", \"raw\")\n",
    "expected_files = [\"labeled.csv\", \"categories.json\"]\n",
    "os.system(f\"rm {raw_crowdsourced_data_path}/*\")\n",
    "\n",
    "start = time.time()\n",
    "utils.download_if_not_present(\n",
    "    dir_path=raw_crowdsourced_data_path,\n",
    "    gdrive_url=\"https://drive.google.com/u/0/uc?id=1U1mDeKOkkdn0yVOGOEUWE7OQcZ_JAV-w&export=download\",\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(\n",
    "    f\"\\n✅ (Down)loaded raw crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "start = time.time()\n",
    "labeled, categories = utils.load(\n",
    "    dir_path=raw_crowdsourced_data_path,\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(f\"✅ Loaded raw crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Processed Crowdsourced data\n",
    "processed_crowdsourced_data_path = os.path.join(\n",
    "    \"..\", \"data\", \"crowdsourced\", \"processed\"\n",
    ")\n",
    "expected_files = [\"websites.csv\", \"content.pkl\"]\n",
    "os.system(f\"rm {processed_crowdsourced_data_path}/*\")\n",
    "\n",
    "start = time.time()\n",
    "utils.download_if_not_present(\n",
    "    dir_path=processed_crowdsourced_data_path,\n",
    "    gdrive_url=\"https://drive.google.com/u/0/uc?id=1Hyg6ASSVIdUHXagx2TUWwjXVIGUTIew_&export=download\",\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(\n",
    "    f\"\\n✅ (Down)loaded processed crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "start = time.time()\n",
    "websites, content = utils.load(\n",
    "    dir_path=processed_crowdsourced_data_path,\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(f\"✅ Loaded crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "websites[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Embedded Crowdsourced data\n",
    "embedded_crowdsourced_data_path = os.path.join(\"..\", \"data\", \"crowdsourced\", \"embedded\")\n",
    "expected_files = [\"embeddings.pt\", \"labels.pt\"]\n",
    "os.system(f\"rm {embedded_crowdsourced_data_path}/*\")\n",
    "\n",
    "start = time.time()\n",
    "utils.download_if_not_present(\n",
    "    dir_path=embedded_crowdsourced_data_path,\n",
    "    gdrive_url=\"https://drive.google.com/u/0/uc?id=1bYLc6DvZZT7JGVrSZjt54Ciw7qH6MMWn&export=download\",\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(f\"\\n✅ (Down)loaded embedded crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "start = time.time()\n",
    "embeddings, labels = utils.load(\n",
    "    dir_path=embedded_crowdsourced_data_path,\n",
    "    expected_files=expected_files,\n",
    ")\n",
    "print(f\"✅ Loaded crowdsourced data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "embeddings.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Curlie data (excludes raw HTML content)\n",
    "curlie_path = os.path.join(conf.DATA_PATH, \"curlie\")\n",
    "os.system(f\"rm {curlie_path}/*\")\n",
    "\n",
    "start = time.time()\n",
    "curlie_data = utils.load_curlie_data(curlie_path)\n",
    "\n",
    "print(f\"\\n✅ (Down)loaded Curlie data ({(time.time() - start):.2f}s).\")\n",
    "\n",
    "start = time.time()\n",
    "curlie_data = utils.load_curlie_data(curlie_path)\n",
    "\n",
    "print(f\"✅ Loaded Curlie data ({(time.time() - start):.2f}s).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-2-mlp-a6NSXBdT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
